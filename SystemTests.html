<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>System Tests</title>
    <link rel="stylesheet" href="_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/custom.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="_static/bootstrap-3.3.7/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="_static/bootstrap-sphinx.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Data Files for Testing" href="DataFilesForTesting.html" />
    <link rel="prev" title="Writing Performance Tests" href="WritingPerformanceTests.html" />

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-59110517-1', 'auto');
  ga('send', 'pageview');

</script>


  </head><body>





  <div id="navbar" class="navbar navbar-default ">
    <div class="container">
      <div class="navbar-header">
        
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="http://www.mantidproject.org"><img src="_static/Mantid_Logo_Transparent.png">
           </a>
        <span class="navbar-text navbar-version pull-left"><b>master</b></span>
      </div>

      
        <div class="collapse navbar-collapse nav-collapse">
      
          <ul class="nav navbar-nav">
            <li class="divider-vertical"></li>
            
                <li><a href="index.html">Home</a></li>
                <li><a href="http://download.mantidproject.org">Download</a></li>
                <li><a href="http://www.mantidproject.org">Wiki</a></li>
                <li><a href="http://docs.mantidproject.org">User Documentation</a></li>
                <li><a href="http://www.mantidproject.org/Contact">Contact Us</a></li>
            
            
              
              
            
            
            
            
          </ul>
              
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
            </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12 content">
      
  <div class="section" id="system-tests">
<span id="systemtests"></span><h1>System Tests<a class="headerlink" href="#system-tests" title="Permalink to this headline">¶</a></h1>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><a class="reference internal" href="#overview" id="id2">Overview</a></li>
<li><a class="reference internal" href="#writing-a-test" id="id3">Writing a Test</a><ul>
<li><a class="reference internal" href="#specifying-validation" id="id4">Specifying Validation</a></li>
<li><a class="reference internal" href="#no-workspace-validation" id="id5">No Workspace Validation</a></li>
<li><a class="reference internal" href="#skipping-tests" id="id6">Skipping tests</a><ul>
<li><a class="reference internal" href="#target-platform-based-on-free-memory" id="id7">Target Platform Based on Free Memory</a></li>
<li><a class="reference internal" href="#id1" id="id8">Target Platform Based on Free Memory</a></li>
</ul>
</li>
<li><a class="reference internal" href="#set-the-tolerance" id="id9">Set the Tolerance</a></li>
<li><a class="reference internal" href="#disable-some-checks" id="id10">Disable Some Checks</a></li>
<li><a class="reference internal" href="#assertions" id="id11">Assertions</a></li>
</ul>
</li>
<li><a class="reference internal" href="#running-tests-locally" id="id12">Running Tests Locally</a><ul>
<li><a class="reference internal" href="#visual-studio-xcode" id="id13">Visual Studio/Xcode</a></li>
<li><a class="reference internal" href="#makefile-like-generators" id="id14">Makefile-like Generators</a></li>
<li><a class="reference internal" href="#selecting-tests-to-run" id="id15">Selecting Tests To Run</a></li>
<li><a class="reference internal" href="#running-the-tests-on-multiple-cores" id="id16">Running the tests on multiple cores</a></li>
<li><a class="reference internal" href="#reducing-the-size-of-console-output" id="id17">Reducing the size of console output</a></li>
<li><a class="reference internal" href="#running-a-cleanup-run" id="id18">Running a cleanup run</a></li>
<li><a class="reference internal" href="#adding-new-data-references-files" id="id19">Adding New Data &amp; References Files</a></li>
</ul>
</li>
<li><a class="reference internal" href="#best-practice" id="id20">Best Practice</a></li>
</ul>
</div>
<div class="section" id="overview">
<h2><a class="toc-backref" href="#id2">Overview</a><a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>System tests are high-level tests, which check that Mantid is able to
reproduce accepted, standardised results as part of its calculations,
when executing user stories. The system test suite is written against
Mantid’s Python API.</p>
<p>As part of our nightly-build and nightly-test procedure, Mantid’s system
tests are run as acceptance tests. The nightly-test jobs deploy a
packaged version of Mantid to the target OS, before executing the system
tests scripts on that environment.</p>
</div>
<div class="section" id="writing-a-test">
<h2><a class="toc-backref" href="#id3">Writing a Test</a><a class="headerlink" href="#writing-a-test" title="Permalink to this headline">¶</a></h2>
<p>The (python) code for the system tests can be found in the git
repository at
<a class="reference external" href="http://github.com/mantidproject/mantid">mantidproject/mantid</a>, under
the <code class="docutils literal notranslate"><span class="pre">Testing/SystemTests</span></code> directory.</p>
<p>Like their ‘stress’ equivalents (<a class="reference external" href="Stress_Tests">stress testing</a>),
system tests inherit from the stresstesting.MantidStressTest class. The
methods that need to be overridden are <code class="docutils literal notranslate"><span class="pre">runTest(self)</span></code>, where the
python code that runs the test should be placed, and <code class="docutils literal notranslate"><span class="pre">validate(self)</span></code>,
which should simply return a pair of strings: the name of the final
workspace that results from the <code class="docutils literal notranslate"><span class="pre">runTest</span></code> method and the name of a
nexus file that should be saved in the ReferenceResults sub-directory in
the repository. The test code itself is likely to be the output of a
<em>Save History</em> command, though it can be any python code. In the
unlikely case of files being used during a system test, implement the
method <code class="docutils literal notranslate"><span class="pre">requiredFiles</span></code> which should return a list of filenames without
paths. The file to validate against should be included as well. If any
of those files are missing the test will be marked as skipped.</p>
<p>The tests should be added to the <code class="docutils literal notranslate"><span class="pre">Testing/SystemTests/tests/analysis</span></code>,
with the template result going in the <code class="docutils literal notranslate"><span class="pre">reference</span></code> sub-folder. It will
then be included in the suite of tests from the following night.</p>
<div class="section" id="specifying-validation">
<h3><a class="toc-backref" href="#id4">Specifying Validation</a><a class="headerlink" href="#specifying-validation" title="Permalink to this headline">¶</a></h3>
<p>You may need to inform the System Test Suite about the format of that
the benchmark workspace you wish to validate against. By default, the
system tests assume that the second argument returned by the validate
tuple is the name of a nexus file to validate against. However you can
override the validateMethod on a test with any one of three options.</p>
<ul class="simple">
<li>WorkspaceToNexus (Benchmark workspace is stored as a Nexus file)
(default)</li>
<li>WorkspaceToWorkspace (Benchmark workspace is stored as a workspace)</li>
<li>ValidateAscii (Benchmark workspace is stored as an ascii file)</li>
</ul>
<p>For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span class="k">def</span> <span class="nf">validateMethod</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="s1">&#39;WorkspaceToNeXus&#39;</span>
</pre></div>
</div>
</div>
<div class="section" id="no-workspace-validation">
<h3><a class="toc-backref" href="#id5">No Workspace Validation</a><a class="headerlink" href="#no-workspace-validation" title="Permalink to this headline">¶</a></h3>
<p>If the system test does not need comparison/validation against a
standard workpace, then this step can be skipped. Simply omitting the</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span class="k">def</span> <span class="nf">validate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</pre></div>
</div>
<p>method from the system test is sufficient.</p>
</div>
<div class="section" id="skipping-tests">
<h3><a class="toc-backref" href="#id6">Skipping tests</a><a class="headerlink" href="#skipping-tests" title="Permalink to this headline">¶</a></h3>
<p>Tests can be skipped based on arbitrary criteria by implementing the
<code class="docutils literal notranslate"><span class="pre">skipTests</span></code> method and returning True if your criteria are met, and
False otherwise. Examples are the availability of a data file or of
certain python modules (e.g. for the XML validation tests).</p>
<div class="section" id="target-platform-based-on-free-memory">
<h4><a class="toc-backref" href="#id7">Target Platform Based on Free Memory</a><a class="headerlink" href="#target-platform-based-on-free-memory" title="Permalink to this headline">¶</a></h4>
<p>Some tests consume a large amount memory resources, and are therefore
best executed on hardware where enough memory is available. You can set
a minimum RAM specification by overriding requiredMemoryMB:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span class="k">def</span> <span class="nf">requiredMemoryMB</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">2000</span>
</pre></div>
</div>
<p>The above function limits the test to run on a machine where there is at
least 2GB of free memory.</p>
</div>
<div class="section" id="id1">
<h4><a class="toc-backref" href="#id8">Target Platform Based on Free Memory</a><a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h4>
<p>Some tests require very large files that cannot be placed in the shared
repository. The <code class="docutils literal notranslate"><span class="pre">requiredFiles()</span></code> method returns a list of these files
so that they test can check that they are all available. If all files
are not available then the tests are skipped.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span class="k">def</span> <span class="nf">requiredFiles</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="s1">&#39;a.nxs&#39;</span><span class="p">,</span> <span class="s1">&#39;b.nxs&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p>The above function limits the test to run on a machine that can find the
files ‘a.nxs’ &amp; ‘b.nxs’</p>
</div>
</div>
<div class="section" id="set-the-tolerance">
<h3><a class="toc-backref" href="#id9">Set the Tolerance</a><a class="headerlink" href="#set-the-tolerance" title="Permalink to this headline">¶</a></h3>
<p>You may specialise the tolerance used by <code class="docutils literal notranslate"><span class="pre">CompareWorkspace</span></code> in your
system test.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span class="bp">self</span><span class="o">.</span><span class="n">tolerance</span> <span class="o">=</span> <span class="mf">0.00000001</span>
</pre></div>
</div>
</div>
<div class="section" id="disable-some-checks">
<h3><a class="toc-backref" href="#id10">Disable Some Checks</a><a class="headerlink" href="#disable-some-checks" title="Permalink to this headline">¶</a></h3>
<p>You may disable some checks performed by the <code class="docutils literal notranslate"><span class="pre">CompareWorkspaces</span></code>
algorithm by appending them to the disableChecking list, which, by
default, is empty.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span class="c1"># A list of things not to check when validating</span>
<span class="bp">self</span><span class="o">.</span><span class="n">disableChecking</span> <span class="o">=</span> <span class="p">[]</span>
</pre></div>
</div>
</div>
<div class="section" id="assertions">
<h3><a class="toc-backref" href="#id11">Assertions</a><a class="headerlink" href="#assertions" title="Permalink to this headline">¶</a></h3>
<p>Additional assertions can be used as the basis for your own comparison
tests. The following assertions are already implemented in the base
class.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span class="k">def</span> <span class="nf">assertTrue</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">msg</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
<span class="k">def</span> <span class="nf">assertEqual</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">expected</span><span class="p">,</span> <span class="n">msg</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
<span class="k">def</span> <span class="nf">assertDelta</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">expected</span><span class="p">,</span> <span class="n">delta</span><span class="p">,</span> <span class="n">msg</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
<span class="k">def</span> <span class="nf">assertLessThan</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">expected</span><span class="p">,</span> <span class="n">msg</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
<span class="k">def</span> <span class="nf">assertGreaterThan</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">expected</span><span class="p">,</span> <span class="n">msg</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="running-tests-locally">
<h2><a class="toc-backref" href="#id12">Running Tests Locally</a><a class="headerlink" href="#running-tests-locally" title="Permalink to this headline">¶</a></h2>
<p>CMake configures a script file called <code class="docutils literal notranslate"><span class="pre">systemtest</span></code> (<code class="docutils literal notranslate"><span class="pre">systemtest.bat</span></code>
on Windows) in the root of the build directory. This file is the driver
script to execute the system tests that runs the lower-level
<code class="docutils literal notranslate"><span class="pre">Testing/SystemTests/scripts/runSystemTests.py</span></code> script but ensures
that the environment is set up correctly for that particular build and
that the required test data has been updated. The script accepts a
<code class="docutils literal notranslate"><span class="pre">-h</span></code> option to print out the standard usage information.</p>
<p>Usage differs depending on whether you are using a single-configuration
generator with CMake, for example Makefiles/Ninja, or a
multi-configuration generator such as Visual Studio or Xcode.</p>
<div class="section" id="visual-studio-xcode">
<h3><a class="toc-backref" href="#id13">Visual Studio/Xcode</a><a class="headerlink" href="#visual-studio-xcode" title="Permalink to this headline">¶</a></h3>
<p>The user must first open command-prompt from, the build directory. The
script requires the developer to select the configuration that will be
used to execute the tests, one of: <em>Release</em>, <em>Debug</em>, <em>RelWithDebInfo</em>
or ‘MinSizeRelease’‘. Note that the script does not build the code so
the chosen configuration must have already been built. An example to
execute all of the tests for the release configuration would be (in the
command-prompt):</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre>&gt; systemtest -C Release
</pre></div>
</div>
</div>
<div class="section" id="makefile-like-generators">
<h3><a class="toc-backref" href="#id14">Makefile-like Generators</a><a class="headerlink" href="#makefile-like-generators" title="Permalink to this headline">¶</a></h3>
<p>The script requires no additional arguments as the configuration is
fixed when running CMake, e.g.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span class="nb">cd</span> build
systemtest
</pre></div>
</div>
</div>
<div class="section" id="selecting-tests-to-run">
<h3><a class="toc-backref" href="#id15">Selecting Tests To Run</a><a class="headerlink" href="#selecting-tests-to-run" title="Permalink to this headline">¶</a></h3>
<p>The most important option on the script is the <code class="docutils literal notranslate"><span class="pre">-R</span></code> option. This
restricts the tests that will run to those that match the given regex,
e.g.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span class="nb">cd</span> build
systemtest -R SNS
<span class="c1"># or for msvc/xcode</span>
systemtest -C &lt;cfg&gt; -R SNS
</pre></div>
</div>
<p>would run all of the tests whose name contains SNS.</p>
</div>
<div class="section" id="running-the-tests-on-multiple-cores">
<h3><a class="toc-backref" href="#id16">Running the tests on multiple cores</a><a class="headerlink" href="#running-the-tests-on-multiple-cores" title="Permalink to this headline">¶</a></h3>
<p>Running the System Tests can be sped up by distributing the list of
tests across multiple cores. This is done in a similar way to <code class="docutils literal notranslate"><span class="pre">ctest</span></code>
using the <code class="docutils literal notranslate"><span class="pre">-j</span> <span class="pre">N</span></code> option, where <code class="docutils literal notranslate"><span class="pre">N</span></code> is the number of cores you want
to use, e.g.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre>./systemtest -j 8
</pre></div>
</div>
<p>would run the tests on 8 cores.</p>
<p>Some tests write or delete in the same directories, using the same file
names, which causes issues when running in parallel. To resolve this,
the tests are grouped in lists where all modules starting with the
same 4 letters are given to one core. This worsens the load balance
between cores (with 8 cores, core 1 performs 93 tests while core 8 only
has 44). This is not ideal but allows the suite to complete without
failures. The runtime using 8 cores still goes down from 2h to 30 min.</p>
<p>This also means that in the case of running a subset of tests with the
<code class="docutils literal notranslate"><span class="pre">-R</span></code> option, if the number of groups created from this is smaller
than the number of cores being used, some cores will have no tests to
run. Using the <code class="docutils literal notranslate"><span class="pre">-j</span></code> option is only really advantageous when running
a large list of tests. It does not bring much speedup up for a small
subset of tests, as these are likely to be put inside the same group
and run on the same core.</p>
</div>
<div class="section" id="reducing-the-size-of-console-output">
<h3><a class="toc-backref" href="#id17">Reducing the size of console output</a><a class="headerlink" href="#reducing-the-size-of-console-output" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">systemtests</span></code> can be run in “quiet” mode using the <code class="docutils literal notranslate"><span class="pre">-q</span></code> or
<code class="docutils literal notranslate"><span class="pre">--quiet</span></code> option. This will print only one line per test instead of
the full log.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre>./systemtest --quiet
Updating testing data...
<span class="o">[</span>100%<span class="o">]</span> Built target StandardTestData
<span class="o">[</span>100%<span class="o">]</span> Built target SystemTestData
Running tests...
FrameworkManager-<span class="o">[</span>Notice<span class="o">]</span> Welcome to Mantid 3.13.20180820.2132
FrameworkManager-<span class="o">[</span>Notice<span class="o">]</span> Please cite: http://dx.doi.org/10.1016/j.nima.2014.07.029 and this release: http://dx.doi.org/10.5286/Software/Mantid
<span class="o">[</span>  0%<span class="o">]</span>   1/435 : DOSTest.DOSCastepTest ............................................... <span class="o">(</span>success: 0.05s<span class="o">)</span>
<span class="o">[</span>  0%<span class="o">]</span>   2/435 : ISISIndirectBayesTest.JumpCETest .................................... <span class="o">(</span>success: 0.06s<span class="o">)</span>
<span class="o">[</span>  0%<span class="o">]</span>   3/435 : ISISIndirectInelastic.IRISCalibration ............................... <span class="o">(</span>success: 0.03s<span class="o">)</span>
<span class="o">[</span>  0%<span class="o">]</span>   4/435 : HFIRTransAPIv2.HFIRTrans1 ........................................... <span class="o">(</span>success: 1.30s<span class="o">)</span>
<span class="o">[</span>  1%<span class="o">]</span>   5/435 : DOSTest.DOSIRActiveTest ............................................. <span class="o">(</span>success: 0.04s<span class="o">)</span>
<span class="o">[</span>  1%<span class="o">]</span>   6/435 : ISISIndirectBayesTest.JumpFickTest .................................. <span class="o">(</span>success: 0.06s<span class="o">)</span>
<span class="o">[</span>  1%<span class="o">]</span>   7/435 : AbinsTest.AbinsBinWidth ............................................. <span class="o">(</span>success: 1.65s<span class="o">)</span>
<span class="o">[</span>  1%<span class="o">]</span>   8/435 : ISIS_PowderPearlTest.CreateCalTest .................................. <span class="o">(</span>success: 1.65s<span class="o">)</span>
<span class="o">[</span>  2%<span class="o">]</span>   9/435 : ISISIndirectInelastic.IRISConvFit ................................... <span class="o">(</span>success: 0.56s<span class="o">)</span>
<span class="o">[</span>  2%<span class="o">]</span>  10/435 : LiquidsReflectometryReductionWithBackgroundTest.BadDataTOFRangeTest . <span class="o">(</span>success: 2.94s<span class="o">)</span>
<span class="o">[</span>  2%<span class="o">]</span>  11/435 : DOSTest.DOSPartialCrossSectionScaleTest ............................. <span class="o">(</span>success: 0.23s<span class="o">)</span>
<span class="o">[</span>  2%<span class="o">]</span>  12/435 : ISISIndirectBayesTest.JumpHallRossTest .............................. <span class="o">(</span>success: 0.07s<span class="o">)</span>
<span class="o">[</span>  2%<span class="o">]</span>  13/435 : ISISIndirectInelastic.IRISDiagnostics ............................... <span class="o">(</span>success: 0.03s<span class="o">)</span>
<span class="o">[</span>  3%<span class="o">]</span>  14/435 : HFIRTransAPIv2.HFIRTrans2 ........................................... <span class="o">(</span>success: 0.83s<span class="o">)</span>
<span class="o">[</span>  3%<span class="o">]</span>  15/435 : DOSTest.DOSPartialSummedContributionsCrossSectionScaleTest .......... <span class="o">(</span>success: 0.15s<span class="o">)</span>
<span class="o">[</span>  3%<span class="o">]</span>  16/435 : ISISIndirectBayesTest.JumpTeixeiraTest .............................. <span class="o">(</span>success: 0.07s<span class="o">)</span>
<span class="o">[</span>  3%<span class="o">]</span>  17/435 : ISISIndirectInelastic.IRISElwinAndMSDFit ............................ <span class="o">(</span>success: 0.29s<span class="o">)</span>
<span class="o">[</span>  4%<span class="o">]</span>  18/435 : MagnetismReflectometryReductionTest.MRFilterCrossSectionsTest ....... <span class="o">(</span>success: 5.30s<span class="o">)</span>
<span class="o">[</span>  4%<span class="o">]</span>  19/435 : DOSTest.DOSPartialSummedContributionsTest ........................... <span class="o">(</span>success: 0.16s<span class="o">)</span>
</pre></div>
</div>
<p>One can recover the full log when a test fails by using the <code class="docutils literal notranslate"><span class="pre">--ouptut-on-failure</span></code> option.</p>
</div>
<div class="section" id="running-a-cleanup-run">
<h3><a class="toc-backref" href="#id18">Running a cleanup run</a><a class="headerlink" href="#running-a-cleanup-run" title="Permalink to this headline">¶</a></h3>
<p>A cleanup run will go through all the tests and call the
<code class="docutils literal notranslate"><span class="pre">.cleanup()</span></code> function for each test. It will not run the tests
(i.e. call the <code class="docutils literal notranslate"><span class="pre">execute()</span></code> function) themselves. This is achieved
by using the <code class="docutils literal notranslate"><span class="pre">-c</span></code> or <code class="docutils literal notranslate"><span class="pre">--clean</span></code> option, e.g.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre>./systemtest -c
</pre></div>
</div>
<p>This is useful if some old data is left over from a previous run,
where some tests were not cleanly exited.</p>
</div>
<div class="section" id="adding-new-data-references-files">
<h3><a class="toc-backref" href="#id19">Adding New Data &amp; References Files</a><a class="headerlink" href="#adding-new-data-references-files" title="Permalink to this headline">¶</a></h3>
<p>The data is managed by CMake’s external data system that is described by
<a class="reference internal" href="DataFilesForTesting.html#datafilesfortesting"><span class="std std-ref">Data Files for Testing</span></a>. Please see <a class="reference internal" href="DataFilesForTesting.html#datafilesfortesting-addinganewfile"><span class="std std-ref">Adding A New File(s)</span></a> for how to add new
files.</p>
</div>
</div>
<div class="section" id="best-practice">
<h2><a class="toc-backref" href="#id20">Best Practice</a><a class="headerlink" href="#best-practice" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Always check your test works locally before making it public.</li>
<li>User stories should come from the users themselves where possible.</li>
<li>Take care to set the tolerance to an acceptable level.</li>
</ul>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
      <ul class="nav navbar-nav" style=" float: right;">
      
      
          
            
  <li>
    <a href="WritingPerformanceTests.html" title="Previous Chapter: Writing Performance Tests"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; Writing Perfo...</span>
    </a>
  </li>
  <li>
    <a href="DataFilesForTesting.html" title="Next Chapter: Data Files for Testing"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">Data Files fo... &raquo;</span>
    </a>
  </li>
          
       
          <li><a href="#">Back to top</a></li>
       </ul>
    <p>
    </p>
  </div>
</footer>
  </body>
</html>