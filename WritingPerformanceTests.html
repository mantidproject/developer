<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Writing Performance Tests</title>
    
    <link rel="stylesheet" href="_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/bootstrap-3.3.6/css/bootstrap.min.css" type="text/css" />
    <link rel="stylesheet" href="_static/bootstrap-3.3.6/css/bootstrap-theme.min.css" type="text/css" />
    <link rel="stylesheet" href="_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="_static/custom.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '3.12.20180705.707',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="_static/bootstrap-3.3.6/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="_static/bootstrap-sphinx.js"></script>
    <link rel="top" title="" href="index.html" />
    <link rel="next" title="System Tests" href="SystemTests.html" />
    <link rel="prev" title="Unit Test Good Practice" href="UnitTestGoodPractice.html" />

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-59110517-1', 'auto');
  ga('send', 'pageview');

</script>


  </head>
  <body role="document">





  <div id="navbar" class="navbar navbar-default ">
    <div class="container">
      <div class="navbar-header">
        
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="http://www.mantidproject.org"><img src="_static/Mantid_Logo_Transparent.png">
           </a>
        <span class="navbar-text navbar-version pull-left"><b>3.12</b></span>
      </div>

      
        <div class="collapse navbar-collapse nav-collapse">
      
          <ul class="nav navbar-nav">
            <li class="divider-vertical"></li>
            
                <li><a href="index.html">Home</a></li>
                <li><a href="http://download.mantidproject.org">Download</a></li>
                <li><a href="http://www.mantidproject.org">Wiki</a></li>
                <li><a href="http://docs.mantidproject.org">User Documentation</a></li>
                <li><a href="http://www.mantidproject.org/Contact">Contact Us</a></li>
            
            
              
              
            
            
            
            
          </ul>
              
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
            </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12 content">
      
  <div class="section" id="writing-performance-tests">
<span id="writingperformancetests"></span><h1>Writing Performance Tests<a class="headerlink" href="#writing-performance-tests" title="Permalink to this headline">¶</a></h1>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><a class="reference internal" href="#overview" id="id1">Overview</a></li>
<li><a class="reference internal" href="#how-to-write-c-performance-tests" id="id2">How to Write C++ Performance Tests</a></li>
<li><a class="reference internal" href="#running-performance-tests" id="id3">Running Performance Tests</a><ul>
<li><a class="reference internal" href="#running-tests-without-ctest" id="id4">Running tests without ctest</a></li>
</ul>
</li>
<li><a class="reference internal" href="#best-practice-advice" id="id5">Best Practice Advice</a></li>
<li><a class="reference internal" href="#jobs-that-monitor-performance" id="id6">Jobs that monitor performance</a></li>
</ul>
</div>
<div class="section" id="overview">
<h2><a class="toc-backref" href="#id1">Overview</a><a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>The point of Performance Tests is to track the performance of a piece of
code through time, so that it will be easy to pinpoint any change that
reduced the performance of a particular bit of code. Performance Tests
will be built and run by a build job, that will track the history of
timing vs revision. The Jenkins job that runs the performance tests
sends out an email when the performance of a test is lowered by more
than a threshold percentage (currently 25%), relative to the average of
a few previous tests.</p>
</div>
<div class="section" id="how-to-write-c-performance-tests">
<h2><a class="toc-backref" href="#id2">How to Write C++ Performance Tests</a><a class="headerlink" href="#how-to-write-c-performance-tests" title="Permalink to this headline">¶</a></h2>
<p>An ideal performance test is neither too fast, nor too slow. The
precision of timing will be insufficient if the test runs in much less
than a second; tests that run for several minutes should also be
avoided.</p>
<p>C++ performance tests are written in the same way as unit tests, and in
the same file as the unit tests for a particular class, except that you
will add <em>Performance</em> to the end of the name of the test suite. For
example, in MyAlgorithmTest.h:</p>
<div class="highlight-c++"><div class="highlight"><pre><span class="k">class</span> <span class="nc">MyAlgorithmTest</span> <span class="o">:</span> <span class="k">public</span> <span class="n">CxxTest</span><span class="o">::</span><span class="n">TestSuite</span> <span class="p">{</span>
   <span class="c1">// Put in your usual, quick unit tests here</span>
<span class="p">};</span>

<span class="k">class</span> <span class="nc">MyAlgorithmTestPerformance</span> <span class="o">:</span> <span class="k">public</span> <span class="n">CxxTest</span><span class="o">::</span><span class="n">TestSuite</span> <span class="p">{</span>
<span class="k">public</span><span class="o">:</span>
   <span class="n">MatrixWorkspace_sptr</span> <span class="n">WS</span><span class="p">;</span>
   <span class="kt">int</span> <span class="n">numpixels</span><span class="p">;</span>

   <span class="kt">void</span> <span class="nf">setUp</span><span class="p">()</span> <span class="p">{</span>
      <span class="c1">// Put in any code needed to set up your test,</span>
      <span class="c1">// but that should NOT be counted in the execution time.</span>
   <span class="p">}</span>

   <span class="kt">void</span> <span class="nf">tearDown</span><span class="p">()</span> <span class="p">{</span>
      <span class="c1">// Clean-up code, also NOT counted in execution time.</span>
   <span class="p">}</span>

   <span class="kt">void</span> <span class="nf">test_slow_performance</span><span class="p">()</span> <span class="p">{</span>
      <span class="c1">// Put in a unit test that will be slow.</span>
   <span class="p">}</span>
<span class="p">};</span>
</pre></div>
</div>
<p>Only the presence/absence of the word Performance is used to determine
if it is a Performance test. As with unit tests, your suite name has to
match the file name.</p>
<p>You may include ASSERT&#8217;s in the same way as a unit test to check that
results are meaningful, but that is unnecessary since these tests are
for performance, not function. Avoid adding so many assert&#8217;s that it
would slow down your test.</p>
</div>
<div class="section" id="running-performance-tests">
<h2><a class="toc-backref" href="#id3">Running Performance Tests</a><a class="headerlink" href="#running-performance-tests" title="Permalink to this headline">¶</a></h2>
<p>Performance tests targets are not added by default when running
cmake/make. To add them as ctest targets, enable them with the flag:</p>
<div class="highlight-sh"><div class="highlight"><pre>cmake -DCXXTEST_ADD_PERFORMANCE<span class="o">=</span>TRUE
</pre></div>
</div>
<p>After re-building, you can then run performance tests with the command:</p>
<div class="highlight-sh"><div class="highlight"><pre>ctest <span class="o">[</span>-C Release<span class="p">|</span>Debug<span class="o">]</span> -R Performance
</pre></div>
</div>
<p>And run regular unit tests, excluding the slow performance ones, with:</p>
<div class="highlight-sh"><div class="highlight"><pre>ctest <span class="o">[</span>-C Release<span class="p">|</span>Debug<span class="o">]</span> -E Performance
</pre></div>
</div>
<p>where the -C option is required for multi-configuration builds like
Visual Studio &amp; XCode.</p>
<p>The resulting .XML files will contain the detailed timing (of just the
test portion without setUp/tearDown time).</p>
<p>Note that newly added performance tests will not be registered with
ctest until cmake has been re-run.</p>
<div class="section" id="running-tests-without-ctest">
<h3><a class="toc-backref" href="#id4">Running tests without ctest</a><a class="headerlink" href="#running-tests-without-ctest" title="Permalink to this headline">¶</a></h3>
<p>The tests are still built into every test executable, even if you have
not set the flag. For example,</p>
<div class="highlight-sh"><div class="highlight"><pre>AlgorithmsTest --help-tests
</pre></div>
</div>
<p>will list all the available tests. If you run</p>
<div class="highlight-sh"><div class="highlight"><pre>AlgorithmsTest
</pre></div>
</div>
<p>alone, it will SKIP the Performance Tests. You have to give the name of
the specific test suite you want to run, e.g,</p>
<div class="highlight-sh"><div class="highlight"><pre>AlgorithmsTest MyAlgorithmPerformanceTest
</pre></div>
</div>
</div>
</div>
<div class="section" id="best-practice-advice">
<h2><a class="toc-backref" href="#id5">Best Practice Advice</a><a class="headerlink" href="#best-practice-advice" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Performance tests are not System Tests. They should test the code at
the same granularity as the unit test suite.</li>
<li>Performance tests are not Unit Tests. There is no need to perform
lots of assertions on the test results.</li>
<li>Performance tests should perform enough work such that statistically
significant performance differences can be measured.</li>
<li>The performance tests are executed often, so ideally they should
typically take 0.2 - 2 seconds to run.</li>
<li>Always perform test set-up outside of the test method. That way your
timings will only relate to the target code you wish to measure.</li>
</ul>
</div>
<div class="section" id="jobs-that-monitor-performance">
<h2><a class="toc-backref" href="#id6">Jobs that monitor performance</a><a class="headerlink" href="#jobs-that-monitor-performance" title="Permalink to this headline">¶</a></h2>
<p>There is a job in Jenkins (our continuous integration system) that runs
the performance test suite and generates output that enables us to
easily monitor timings. The job runs a set of <a class="reference external" href="http://builds.mantidproject.org/job/master_performancetests2/">performance tests on the
master branch of
Mantid</a>.
This job runs on a machine at the ESS, everytime that changes are merged
into the Mantid master branch, and stores the timing information in a
database, also generating HTML output via a <a class="reference external" href="https://github.com/mantidproject/mantid/tree/master/Testing/PerformanceTests">set of python
scripts</a>.</p>
<p>The timing output of these jobs are typically monitored manually on a
weekly basis to pick up any notable performance degradation. Although
automatic checking is available within the python scripts, the level of
instability in the timings meant that it always produced way too many
false positives to be useful.</p>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
      <ul class="nav navbar-nav" style=" float: right;">
      
      
          
            
  <li>
    <a href="UnitTestGoodPractice.html" title="Previous Chapter: Unit Test Good Practice"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; Unit Test Goo...</span>
    </a>
  </li>
  <li>
    <a href="SystemTests.html" title="Next Chapter: System Tests"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">System Tests &raquo;</span>
    </a>
  </li>
          
       
          <li><a href="#">Back to top</a></li>
       </ul>
    <p>
    </p>
  </div>
</footer>
  </body>
</html>